{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import dask.dataframe as dd\n",
    "from tsfresh import extract_relevant_features\n",
    "from tsfresh.utilities.dataframe_functions import roll_time_series, make_forecasting_frame\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (10, 8)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eurusd_ask_file_path = r'/root/workspace/Autoformer/dataset/forex/EURUSD_Candlestick_1_M_ASK_07.07.2020-07.07.2023.csv'\n",
    "eurusd_bid_file_path = r'/root/workspace/Autoformer/dataset/forex/EURUSD_Candlestick_1_M_BID_07.07.2020-07.07.2023.csv'\n",
    "\n",
    "# Read CSV files into Dask DataFrames\n",
    "eurusd_ask_dataset = dd.read_csv(eurusd_ask_file_path)\n",
    "eurusd_bid_dataset = dd.read_csv(eurusd_bid_file_path)\n",
    "\n",
    "# Convert 'Gmt time' columns to datetime\n",
    "eurusd_ask_dataset['Gmt time'] = dd.to_datetime(eurusd_ask_dataset['Gmt time'], format='%d.%m.%Y %H:%M:%S.%f')\n",
    "eurusd_bid_dataset['Gmt time'] = dd.to_datetime(eurusd_bid_dataset['Gmt time'], format='%d.%m.%Y %H:%M:%S.%f')\n",
    "\n",
    "# Rename columns\n",
    "ask_rename_dict = {col: f'eurusd_ask_{col}' for col in eurusd_ask_dataset.columns if col != 'Gmt time'}\n",
    "eurusd_ask_dataset = eurusd_ask_dataset.rename(columns=ask_rename_dict)\n",
    "\n",
    "bid_rename_dict = {col: f'eurusd_bid_{col}' for col in eurusd_bid_dataset.columns if col != 'Gmt time'}\n",
    "eurusd_bid_dataset = eurusd_bid_dataset.rename(columns=bid_rename_dict)\n",
    "\n",
    "# Merge datasets\n",
    "eurusd_dataset = dd.merge(eurusd_ask_dataset, eurusd_bid_dataset, left_on='Gmt time', right_on='Gmt time', how='inner')\n",
    "\n",
    "# Filtering by weekday\n",
    "eurusd_dataset = eurusd_dataset[eurusd_dataset['Gmt time'].dt.weekday < 5]\n",
    "\n",
    "# Linearly interpolate missing values using Dask's map_partitions with pandas interpolate\n",
    "eurusd_dataset = eurusd_dataset.map_partitions(lambda df: df.interpolate(method='linear'))\n",
    "\n",
    "# Drop 'Gmt time' and set 'Gmt time' as index\n",
    "eurusd_dataset = eurusd_dataset.set_index('Gmt time')\n",
    "\n",
    "# Create the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to your data and transform it\n",
    "eurusd_dataset = eurusd_dataset.persist()\n",
    "normalized_data = scaler.fit_transform(eurusd_dataset)\n",
    "\n",
    "# Convert back to Dask DataFrame\n",
    "normalized_dataset = dd.from_pandas(pd.DataFrame(normalized_data, columns=eurusd_dataset.columns), npartitions=eurusd_dataset.npartitions)\n",
    "\n",
    "# Reset index and add a constant 'id' column\n",
    "normalized_dataset = normalized_dataset.reset_index()\n",
    "normalized_dataset['id'] = 0\n",
    "\n",
    "# Convert to pandas DataFrame if needed\n",
    "normalized_dataset = normalized_dataset.compute()\n",
    "\n",
    "# Display the final dataset\n",
    "print(normalized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your dataset has 'date' as the time column and 'id' as an identifier\n",
    "# (based on previous interactions)\n",
    "df_rolled = roll_time_series(normalized_dataset, column_id=\"id\", column_sort=\"index\", max_timeshift=20, min_timeshift=5, rolling_direction=1, chunksize=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, extract features from this rolled data:\n",
    "df_features = extract_relevant_features(df_rolled, column_id=\"id\", column_sort=\"date\")\n",
    "\n",
    "# If you want to create a target vector for forecasting:\n",
    "# (Replace 'price_column' with whatever column you're trying to forecast)\n",
    "df_shift, y = make_forecasting_frame(dataset[\"eurusd_ask_Close\"], kind=\"price\", max_timeshift=20, rolling_direction=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0 \n",
    "for i in df_shift.columns:\n",
    "    num += 1\n",
    "\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shift.to_csv('/root/workspace/Autoformer/dataset/forex/Preprocessed_EURUSD_Candlestick_1_M_ASKBID_07.07.2020-07.07.2023.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
